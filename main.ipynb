{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTE R TO PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup \n",
    "\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import statsmodels.genmod.generalized_linear_model as sm\n",
    "sm.SET_USE_BIC_LLF(True)\n",
    "\n",
    "# Create directories\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Setup trial sequences as dictionaries\n",
    "trial_pp = {\"estimand\": \"PP\", \"dir\": trial_pp_dir}\n",
    "trial_itt = {\"estimand\": \"ITT\", \"dir\": trial_itt_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used dictionaries to store trial settings and os to create directories. \n",
    "Since there's no direct equivalent to trial_sequence(), so I mimiced the structure at \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "os.makedirs(..., exist_ok=True) ensures directories are created without raising an error if they already exist. <br>\n",
    "\n",
    "The trial objects (trial_pp, trial_itt) are dictionaries that will hold all trial-related data and settings.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used. In the original R code, a parameter called ``` time_on_regime``` is shown on the other steps, however it is only retrieved through ``` switch_n_cov```: \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "switch_n_cov<br>\n",
    "A RHS formula to specify the logistic models for estimating the numerator terms of the inverse probability of treatment weights. A derived variable named time_on_regime containing the duration of time that the individual has been on the current treatment/non-treatment is available for use in these models.\n",
    "</div>\n",
    "\n",
    "Upon checking further, time_on_regime isn't used in any significant functions, so I decided to omit it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "5   1       5          1   0 -0.057482   0  0.734203   41  0.500000        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "5         1         0  \n"
     ]
    }
   ],
   "source": [
    "# Load data (assuming it's saved as a CSV)\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "columns = {\n",
    "    \"id\": \"id\",\n",
    "    \"period\": \"period\",\n",
    "    \"treatment\": \"treatment\",\n",
    "    \"outcome\": \"outcome\",\n",
    "    \"eligible\": \"eligible\"\n",
    "}\n",
    "\n",
    "# Assign data and columns to trials\n",
    "trial_pp[\"data\"] = data_censored.copy()\n",
    "trial_pp[\"columns\"] = columns\n",
    "\n",
    "trial_itt[\"data\"] = data_censored.copy()\n",
    "trial_itt[\"columns\"] = columns\n",
    "\n",
    "# Display the first 6 rows (equivalent to head() in R showing 6 rows)\n",
    "print(data_censored.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded the data from the CSV file and store it in the trial dictionaries. \n",
    "\n",
    "Used ```python pd.read_csv()``` instead of ```R data(\"data_censored\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 6 rows of data_censored:\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "5   1       5          1   0 -0.057482   0  0.734203   41  0.500000        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "5         1         0  \n",
      "\n",
      "Trial ITT Summary:\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      "                 id      period   treatment          x1          x2          x3          x4         age       age_s     outcome    censored    eligible\n",
      "              <int>       <int>       <int>       <int>       <num>       <int>       <num>       <int>       <num>       <int>       <int>       <int>\n",
      "   0:           1           0           1           1    1.146148           0    0.734203          36    0.083333           0           0           1\n",
      "   1:           1           1           1           1    0.002200           0    0.734203          37    0.166667           0           0           0\n",
      "    ...\n",
      " 723:          99           6           1           1   -0.033762           1    0.575268          71    3.000000           0           0           0\n",
      " 724:          99           7           0           0   -1.340497           1    0.575268          72    3.083333           1           0           0\n",
      "\n",
      "IPW for informative censoring:\n",
      " - Not specified\n",
      "\n",
      "Sequence of Trials Data:\n",
      " - Not specified\n",
      "\n",
      "Outcome model:\n",
      " - Not specified\n"
     ]
    }
   ],
   "source": [
    "def set_data(trial, data, id, period, treatment, outcome, eligible):\n",
    "    trial[\"data\"] = data.copy()\n",
    "    trial[\"columns\"] = {\n",
    "        \"id\": id,\n",
    "        \"period\": period,\n",
    "        \"treatment\": treatment,\n",
    "        \"outcome\": outcome,\n",
    "        \"eligible\": eligible\n",
    "    }\n",
    "    trial[\"n_observations\"] = len(data)\n",
    "    trial[\"n_patients\"] = data[id].nunique()\n",
    "    \n",
    "    # Initialize missing keys with default status\n",
    "    trial[\"censor_weights\"] = {\"status\": \"Not specified\"}\n",
    "    trial[\"expansion\"] = {\"status\": \"Not specified\"}\n",
    "    trial[\"outcome_model\"] = {\"status\": \"Not specified\"}\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Function to display trial object summary\n",
    "def print_trial_summary(trial):\n",
    "    print(\"Trial Sequence Object\")\n",
    "    print(f\"Estimand: {trial['estimand']}\")\n",
    "    print(\"\")\n",
    "    print(\"Data:\")\n",
    "    print(f\" - N: {trial['n_observations']} observations from {trial['n_patients']} patients\")\n",
    "    \n",
    "    # Select the desired columns\n",
    "    display_cols = [\"id\", \"period\", \"treatment\", \"x1\", \"x2\", \"x3\", \"x4\", \"age\", \"age_s\", \n",
    "                    \"outcome\", \"censored\", \"eligible\"]\n",
    "    data_display = pd.concat([trial[\"data\"][display_cols].head(2), trial[\"data\"][display_cols].tail(2)])\n",
    "    \n",
    "    # Define column types\n",
    "    col_types = {col: \"<int>\" if trial[\"data\"][col].dtype == \"int64\" else \"<num>\" for col in display_cols}\n",
    "    \n",
    "    # Print column headers and types\n",
    "    print(\"        \" + \" \".join(f\"{col:>11}\" for col in display_cols))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:>11}\" for col in display_cols))\n",
    "    \n",
    "    # Print rows dynamically with their actual indices\n",
    "    for i, (idx, row) in enumerate(data_display.iterrows()):\n",
    "        # Right-align the index with a colon, adjusting width to fit larger numbers\n",
    "        label = f\"{idx:>4}:\"\n",
    "        print(label, end=\" \")\n",
    "        formatted_row = [f\"{row[col]:>11.6f}\" if col_types[col] == \"<num>\" else f\"{int(row[col]):>11}\" for col in display_cols]\n",
    "        print(\" \".join(formatted_row))\n",
    "        # Add ellipsis after the second row (before the last two)\n",
    "        if i == 1:\n",
    "            print(\"    ...\")\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"IPW for informative censoring:\")\n",
    "    print(f\" - {trial['censor_weights']['status']}\")\n",
    "    print(\"\")\n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(f\" - {trial['expansion']['status']}\")\n",
    "    print(\"\")\n",
    "    print(\"Outcome model:\")\n",
    "    print(f\" - {trial['outcome_model']['status']}\")\n",
    "\n",
    "# Per-protocol\n",
    "trial_pp = set_data(\n",
    "    trial_pp,\n",
    "    data=data_censored,\n",
    "    id=\"id\",\n",
    "    period=\"period\",\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    eligible=\"eligible\"\n",
    ")\n",
    "\n",
    "# ITT\n",
    "trial_itt = set_data(\n",
    "    trial_itt,\n",
    "    data=data_censored,\n",
    "    id=\"id\",\n",
    "    period=\"period\",\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    eligible=\"eligible\"\n",
    ")\n",
    "\n",
    "# Display the first 6 rows\n",
    "print(\"First 6 rows of data_censored:\")\n",
    "print(data_censored.head(6))\n",
    "\n",
    "# Display trial_itt summary\n",
    "print(\"\\nTrial ITT Summary:\")\n",
    "print_trial_summary(trial_itt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Weight models and censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weight Config for trial_pp:\n",
      "Numerator formula: 1 - censored ~ treatment ~ age\n",
      "Denominator formula: 1 - censored ~ treatment ~ age + x1 + x3\n",
      "Model fitter type: te_stats_glm_logit\n",
      "Weight models not fitted. Use calculate_weights()\n",
      "\n",
      "Censor Weight Config for trial_pp:\n",
      "Numerator formula: 1 - censored ~ x2\n",
      "Denominator formula: 1 - censored ~ x2 + x1\n",
      "Model fitter type: te_stats_glm_logit\n",
      "Weight models not fitted. Use calculate_weights()\n",
      "\n",
      "Censor Weight Config for trial_itt:\n",
      "Numerator formula: 1 - censored ~ x2\n",
      "Denominator formula: 1 - censored ~ x2 + x1\n",
      "Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      "Model fitter type: te_stats_glm_logit\n",
      "Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# --- Section 3: Weight Models and Censoring ---\n",
    "def set_weight_models(trial, weight_type, censor_event=None, numerator_vars=None, denominator_vars=None, pool_models=\"none\", save_path=None):\n",
    "    # Store configuration without fitting models yet\n",
    "    trial[f\"{weight_type}_config\"] = {\n",
    "        \"censor_event\": censor_event,\n",
    "        \"numerator_vars\": numerator_vars,\n",
    "        \"denominator_vars\": denominator_vars,\n",
    "        \"pool_models\": pool_models,\n",
    "        \"save_path\": save_path,\n",
    "        \"fitted\": False\n",
    "    }\n",
    "\n",
    "def show_weight_config(trial, weight_type):\n",
    "    config = trial.get(f\"{weight_type}_config\", {})\n",
    "    if not config:\n",
    "        return\n",
    "    print(f\"Numerator formula: 1 - censored ~ {' + '.join(config['numerator_vars']) if weight_type == 'censor' else 'treatment ~ ' + ' + '.join(config['numerator_vars'])}\")\n",
    "    print(f\"Denominator formula: 1 - censored ~ {' + '.join(config['denominator_vars']) if weight_type == 'censor' else 'treatment ~ ' + ' + '.join(config['denominator_vars'])}\")\n",
    "    if weight_type == \"censor\" and config[\"pool_models\"] == \"numerator\":\n",
    "        print(\"Numerator model is pooled across treatment arms. Denominator model is not pooled.\")\n",
    "    print(\"Model fitter type: te_stats_glm_logit\")\n",
    "    print(\"Weight models not fitted. Use calculate_weights()\")\n",
    "\n",
    "# Set and show switch weight models (PP only)\n",
    "set_weight_models(\n",
    "    trial_pp,\n",
    "    weight_type=\"switch\",\n",
    "    numerator_vars=[\"age\"],\n",
    "    denominator_vars=[\"age\", \"x1\", \"x3\"],\n",
    "    save_path=os.path.join(trial_pp[\"dir\"], \"switch_models\")\n",
    ")\n",
    "print(\"Switch Weight Config for trial_pp:\")\n",
    "show_weight_config(trial_pp, \"switch\")\n",
    "\n",
    "# Set and show censor weight models (PP)\n",
    "set_weight_models(\n",
    "    trial_pp,\n",
    "    weight_type=\"censor\",\n",
    "    censor_event=\"censored\",\n",
    "    numerator_vars=[\"x2\"],\n",
    "    denominator_vars=[\"x2\", \"x1\"],\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp[\"dir\"], \"switch_models\")\n",
    ")\n",
    "print(\"\\nCensor Weight Config for trial_pp:\")\n",
    "show_weight_config(trial_pp, \"censor\")\n",
    "\n",
    "# Set and show censor weight models (ITT)\n",
    "set_weight_models(\n",
    "    trial_itt,\n",
    "    weight_type=\"censor\",\n",
    "    censor_event=\"censored\",\n",
    "    numerator_vars=[\"x2\"],\n",
    "    denominator_vars=[\"x2\", \"x1\"],\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt[\"dir\"], \"switch_models\")\n",
    ")\n",
    "print(\"\\nCensor Weight Config for trial_itt:\")\n",
    "show_weight_config(trial_itt, \"censor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Models for trial_itt:\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[n]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    2.4480907 0.1405747 17.414876 6.362614e-68\n",
      "x2           -0.4486482 0.1368779 -3.277724 1.046476e-03\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "404.2155891     724 -196.7002 397.4004  406.5727 393.4004     723     725\n",
      " \n",
      "\n",
      "[d0]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    1.8941961 0.2071136  9.145686 5.925282e-20\n",
      "x2           -0.5898292 0.1693423 -3.483059 4.957189e-04\n",
      "x1           0.8552603 0.3452990  2.476869 1.325407e-02\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "283.0722903     425 -132.1655 270.3309  282.4943 264.3309     423     426\n",
      " \n",
      "\n",
      "[d1]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    2.8144337 0.3122688  9.012857 2.007570e-19\n",
      "x2           -0.0371320 0.2699579 -0.137547 8.905983e-01\n",
      "x1           0.8935142 0.7771954  1.149665 2.502819e-01\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "113.0528189     298  -55.7294 117.4588  128.5601 111.4588     296     299\n",
      " \n",
      "\n",
      "\n",
      "Weight Models for trial_pp:\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[n0]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for numerator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    2.2450083 0.1717699 13.069858 4.895660e-39\n",
      "x2           -0.5739410 0.1670093 -3.436581 5.891065e-04\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "283.0722903     425 -135.4361 274.8722  282.9811 270.8722     424     426\n",
      " \n",
      "\n",
      "[d0]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    1.8941961 0.2071136  9.145686 5.925282e-20\n",
      "x2           -0.5898292 0.1693423 -3.483059 4.957189e-04\n",
      "x1           0.8552603 0.3452990  2.476869 1.325407e-02\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "283.0722903     425 -132.1655 270.3309  282.4943 264.3309     423     426\n",
      " \n",
      "\n",
      "[n1]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for numerator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    3.0115791 0.2873389 10.480931 1.056984e-25\n",
      "x2           -0.0056924 0.2705060 -0.021044 9.832108e-01\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "113.0528189     298  -56.5262 117.0524  124.4533 113.0524     297     299\n",
      " \n",
      "\n",
      "[d1]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    2.8144337 0.3122688  9.012857 2.007570e-19\n",
      "x2           -0.0371320 0.2699579 -0.137547 8.905983e-01\n",
      "x1           0.8935142 0.7771954  1.149665 2.502819e-01\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "113.0528189     298  -55.7294 117.4588  128.5601 111.4588     296     299\n",
      " \n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "---------------------------------------\n",
      "\n",
      "[n1]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for numerator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    2.0396103 0.5420919  3.762481 1.682362e-04\n",
      "age          -0.0310522 0.0110459 -2.811186 4.935922e-03\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "391.1564623     298 -191.4956 386.9911  394.3920 382.9911     297     299\n",
      " \n",
      "\n",
      "[d1]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    1.7547325 0.5860355  2.994243 2.751272e-03\n",
      "age          -0.0302930 0.0112795 -2.685678 7.238286e-03\n",
      "x1           0.6544038 0.2891611  2.263112 2.362881e-02\n",
      "x3           0.1615074 0.2501787  0.645568 5.185589e-01\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "391.1564623     298 -188.6727 385.3454  400.1472 377.3454     295     299\n",
      " \n",
      "\n",
      "[n0]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for numerator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    1.5948828 0.4380994  3.640459 2.721526e-04\n",
      "age          -0.0462893 0.0089922 -5.147747 2.636339e-07\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "550.2501508     425 -260.8109 525.6219  533.7307 521.6219     424     426\n",
      " \n",
      "\n",
      "[d0]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for denominator\n",
      " \n",
      "term        estimate   std.error statistic p.value\n",
      "Intercept    1.4906935 0.4708148  3.166199 1.544450e-03\n",
      "age          -0.0491250 0.0092132 -5.332051 9.710981e-08\n",
      "x1           0.5951259 0.2149546  2.768611 5.629574e-03\n",
      "x3           -0.1392974 0.2141210 -0.650555 5.153341e-01\n",
      " \n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "550.2501508     425 -256.6657 521.3314  537.5492 513.3314     422     426\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_weight_models(trial, weight_type):\n",
    "    \"\"\"\n",
    "    Fit numerator and denominator models for switch or censor weights based on trial configuration.\n",
    "    \"\"\"\n",
    "    config = trial[f\"{weight_type}_config\"]\n",
    "    data = trial[\"data\"].copy()\n",
    "    models = {}\n",
    "    \n",
    "    if weight_type == \"switch\":\n",
    "        # Compute previous treatment for switch weights\n",
    "        data['prev_treatment'] = data.groupby('id')['treatment'].shift(1).fillna(0).astype(int)\n",
    "        groups = data.groupby('prev_treatment')\n",
    "        outcome = 'treatment'\n",
    "        formula_num = f\"{outcome} ~ {' + '.join(config['numerator_vars'])}\"\n",
    "        formula_den = f\"{outcome} ~ {' + '.join(config['denominator_vars'])}\"\n",
    "        for group_name, group_data in groups:\n",
    "            model_num = smf.glm(formula_num, data=group_data, family=sm.families.Binomial()).fit()\n",
    "            model_den = smf.glm(formula_den, data=group_data, family=sm.families.Binomial()).fit()\n",
    "            models[f\"n{group_name}\"] = model_num\n",
    "            models[f\"d{group_name}\"] = model_den\n",
    "    \n",
    "    elif weight_type == \"censor\":\n",
    "        outcome = config[\"censor_event\"]\n",
    "        # Define outcome as not censored (1 - censor_event)\n",
    "        data['not_censored'] = 1 - data[outcome]\n",
    "        # Compute previous treatment for censor weights\n",
    "        data['prev_treatment'] = data.groupby('id')['treatment'].shift(1).fillna(0).astype(int)\n",
    "        if config[\"pool_models\"] == \"numerator\":  # ITT case\n",
    "            # Pooled numerator model across all data\n",
    "            formula_num = f\"not_censored ~ {' + '.join(config['numerator_vars'])}\"\n",
    "            model_num = smf.glm(formula_num, data=data, family=sm.families.Binomial()).fit()\n",
    "            models[\"n\"] = model_num\n",
    "            # Separate denominator models by prev_treatment\n",
    "            formula_den = f\"not_censored ~ {' + '.join(config['denominator_vars'])}\"\n",
    "            for group_name, group_data in data.groupby('prev_treatment'):\n",
    "                model_den = smf.glm(formula_den, data=group_data, family=sm.families.Binomial()).fit()\n",
    "                models[f\"d{group_name}\"] = model_den\n",
    "        else:  # PP case, no pooling\n",
    "            formula_num = f\"not_censored ~ {' + '.join(config['numerator_vars'])}\"\n",
    "            formula_den = f\"not_censored ~ {' + '.join(config['denominator_vars'])}\"\n",
    "            for group_name, group_data in data.groupby('prev_treatment'):\n",
    "                model_num = smf.glm(formula_num, data=group_data, family=sm.families.Binomial()).fit()\n",
    "                model_den = smf.glm(formula_den, data=group_data, family=sm.families.Binomial()).fit()\n",
    "                models[f\"n{group_name}\"] = model_num\n",
    "                models[f\"d{group_name}\"] = model_den\n",
    "    \n",
    "    trial[f\"{weight_type}_models\"] = models\n",
    "    config[\"fitted\"] = True\n",
    "\n",
    "def calculate_weights(trial, weight_type):\n",
    "    \"\"\"\n",
    "    Calculate weights using fitted models. Fit models if not already fitted.\n",
    "    \"\"\"\n",
    "    if not trial[f\"{weight_type}_config\"][\"fitted\"]:\n",
    "        fit_weight_models(trial, weight_type)\n",
    "    \n",
    "    data = trial[\"data\"].copy()\n",
    "    models = trial[f\"{weight_type}_models\"]\n",
    "    \n",
    "    if weight_type == \"switch\":\n",
    "        if 'prev_treatment' not in data.columns:\n",
    "            data['prev_treatment'] = data.groupby('id')['treatment'].shift(1).fillna(0).astype(int)\n",
    "        weights = pd.Series(index=data.index, dtype=float)\n",
    "        for group_name in [0, 1]:\n",
    "            group_data = data[data['prev_treatment'] == group_name]\n",
    "            idx = group_data.index\n",
    "            prob_num = models[f\"n{group_name}\"].predict(group_data)\n",
    "            prob_den = models[f\"d{group_name}\"].predict(group_data)\n",
    "            weights.loc[idx] = np.where(group_data['treatment'] == 1, prob_num / prob_den, (1 - prob_num) / (1 - prob_den))\n",
    "        data[\"wt\"] = weights\n",
    "    \n",
    "    elif weight_type == \"censor\":\n",
    "        if 'prev_treatment' not in data.columns:\n",
    "            data['prev_treatment'] = data.groupby('id')['treatment'].shift(1).fillna(0).astype(int)\n",
    "        weights = pd.Series(index=data.index, dtype=float)\n",
    "        if \"n\" in models:  # ITT with pooled numerator\n",
    "            prob_num = models[\"n\"].predict(data)\n",
    "            for group_name in [0, 1]:\n",
    "                group_data = data[data['prev_treatment'] == group_name]\n",
    "                idx = group_data.index\n",
    "                prob_den = models[f\"d{group_name}\"].predict(group_data)\n",
    "                weights.loc[idx] = prob_num.loc[idx] / prob_den\n",
    "        else:  # PP with separate models\n",
    "            for group_name in [0, 1]:\n",
    "                group_data = data[data['prev_treatment'] == group_name]\n",
    "                idx = group_data.index\n",
    "                prob_num = models[f\"n{group_name}\"].predict(group_data)\n",
    "                prob_den = models[f\"d{group_name}\"].predict(group_data)\n",
    "                weights.loc[idx] = prob_num / prob_den\n",
    "        data[\"wtC\"] = weights\n",
    "    \n",
    "    trial[\"data\"] = data\n",
    "\n",
    "def show_weight_models(trial):\n",
    "    \"\"\"\n",
    "    Display summaries of fitted weight models with specified descriptions and order.\n",
    "    \"\"\"\n",
    "    weight_types = [\"censor\", \"switch\"] if trial[\"estimand\"] == \"PP\" else [\"censor\"]\n",
    "    for weight_type in weight_types:\n",
    "        if f\"{weight_type}_models\" not in trial:\n",
    "            continue\n",
    "        print(f\"Weight Models for {'Informative Censoring' if weight_type == 'censor' else 'Treatment Switching'}\")\n",
    "        print(\"---------------------------------------\\n\")\n",
    "        models = trial[f\"{weight_type}_models\"]\n",
    "        \n",
    "        # Set display order based on estimand\n",
    "        if weight_type == \"censor\":\n",
    "            if trial[f\"{weight_type}_config\"][\"pool_models\"] == \"numerator\":\n",
    "                order = [\"n\", \"d0\", \"d1\"]  # ITT order\n",
    "            else:\n",
    "                order = [\"n0\", \"d0\", \"n1\", \"d1\"]  # PP order\n",
    "        else:  # switch weights for PP\n",
    "            order = [\"n1\", \"d1\", \"n0\", \"d0\"]\n",
    "        \n",
    "        for model_key in order:\n",
    "            if model_key in models:\n",
    "                model = models[model_key]\n",
    "                is_numerator = model_key.startswith('n')\n",
    "                group_name = model_key[1:] if model_key != \"n\" else \"\"\n",
    "                if weight_type == \"switch\":\n",
    "                    desc = f\"P(treatment = 1 | previous treatment = {group_name}) for {'numerator' if is_numerator else 'denominator'}\"\n",
    "                else:\n",
    "                    if model_key == \"n\":\n",
    "                        desc = \"P(censor_event = 0 | X) for numerator\"  # ITT pooled numerator\n",
    "                    else:\n",
    "                        desc = f\"P(censor_event = 0 | X, previous treatment = {group_name}) for {'numerator' if is_numerator else 'denominator'}\"\n",
    "                print(f\"[{model_key}]\")\n",
    "                print(f\"Model: {desc}\")\n",
    "                print(\" \")\n",
    "                print(\"term        estimate   std.error statistic p.value\")\n",
    "                params = model.params\n",
    "                std_err = model.bse\n",
    "                tvalues = model.tvalues\n",
    "                pvalues = model.pvalues\n",
    "                for term in params.index:\n",
    "                    print(f\"{term:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {tvalues[term]:>9.6f} {pvalues[term]:.6e}\")\n",
    "                print(\" \")\n",
    "                print(f\"null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "                print(f\"{model.null_deviance:.7f} {int(model.nobs-1):>7} {model.llf:>9.4f} {model.aic:>7.4f} {model.bic:>9.4f} {model.deviance:>7.4f} {int(model.df_resid):>7} {int(model.nobs):>7}\")\n",
    "                print(\" \\n\")\n",
    "# Execute calculations\n",
    "calculate_weights(trial_pp, \"switch\")\n",
    "calculate_weights(trial_pp, \"censor\")\n",
    "calculate_weights(trial_itt, \"censor\")\n",
    "\n",
    "# Display results\n",
    "print(\"Weight Models for trial_itt:\")\n",
    "show_weight_models(trial_itt)\n",
    "print(\"\\nWeight Models for trial_pp:\")\n",
    "show_weight_models(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome model for PP: outcome ~ assigned_treatment + age\n",
      "Outcome model for ITT: outcome ~ assigned_treatment + x2\n",
      "Expansion options set for PP: chunk_size=500, output_format=dataframe\n",
      "Expansion options set for ITT: chunk_size=500, output_format=dataframe\n",
      "Expanded data for PP: 1450 rows\n",
      "Expanded data for ITT: 1450 rows\n",
      "trial_itt before set_outcome_model: {'estimand': 'ITT', 'dir': 'c:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\Clustering-Assignment-1\\\\trial_itt', 'data':      id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
      "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
      "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
      "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
      "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
      "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
      "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
      "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
      "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
      "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
      "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
      "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
      "\n",
      "     outcome  censored  eligible  \n",
      "0          0         0         1  \n",
      "1          0         0         0  \n",
      "2          0         0         0  \n",
      "3          0         0         0  \n",
      "4          0         0         0  \n",
      "..       ...       ...       ...  \n",
      "720        0         0         0  \n",
      "721        0         0         0  \n",
      "722        0         0         0  \n",
      "723        0         0         0  \n",
      "724        1         0         0  \n",
      "\n",
      "[725 rows x 12 columns], 'columns': {'id': 'id', 'period': 'period', 'treatment': 'treatment', 'outcome': 'outcome', 'eligible': 'eligible'}, 'n_observations': 725, 'n_patients': 89, 'censor_weights': {'status': 'Not specified'}, 'expansion': {'status': 'Not specified'}, 'outcome_model': {'status': 'Not specified'}}\n",
      "Outcome model for ITT: outcome ~ assigned_treatment + x2\n",
      "PEEPEE\n",
      "Warning: Column 'followup_time' not found in expanded data.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Specify Outcome Model\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    base_formula = \"outcome ~ assigned_treatment\"\n",
    "    \n",
    "    if trial[\"estimand\"] == \"PP\" and \"switch_config\" in trial:\n",
    "        numerator_vars = trial[\"switch_config\"][\"numerator_vars\"]\n",
    "        additional_terms = \" + \".join(numerator_vars)\n",
    "        trial[\"outcome_model\"] = f\"{base_formula} + {additional_terms}\"\n",
    "    elif adjustment_terms:\n",
    "        trial[\"outcome_model\"] = f\"{base_formula} + {adjustment_terms}\"\n",
    "    else:\n",
    "        trial[\"outcome_model\"] = base_formula\n",
    "    \n",
    "    print(f\"Outcome model for {trial['estimand']}: {trial['outcome_model']}\")\n",
    "    return trial\n",
    "\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Step 6: Expand Trials\n",
    "def set_expansion_options(trial, chunk_size=500, output_format=\"dataframe\"):\n",
    "    trial[\"expansion_options\"] = {\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"output_format\": output_format\n",
    "    }\n",
    "    print(f\"Expansion options set for {trial['estimand']}: chunk_size={chunk_size}, output_format={output_format}\")\n",
    "    return trial\n",
    "\n",
    "def expand_trials(trial):\n",
    "    data = trial[\"data\"]\n",
    "    chunk_size = trial[\"expansion_options\"][\"chunk_size\"]\n",
    "    expanded_data = []\n",
    "    \n",
    "    for start in range(0, len(data), chunk_size):\n",
    "        chunk = data.iloc[start:start + chunk_size].copy()\n",
    "        for treatment in [0, 1]:\n",
    "            chunk_copy = chunk.copy()\n",
    "            chunk_copy[\"assigned_treatment\"] = treatment\n",
    "            # Ensure trial_period is present\n",
    "            if \"period\" in chunk_copy.columns:\n",
    "                chunk_copy[\"trial_period\"] = chunk_copy[\"period\"]\n",
    "            else:\n",
    "                chunk_copy[\"trial_period\"] = start // chunk_size  # Example: period based on chunk index\n",
    "            expanded_data.append(chunk_copy)\n",
    "    \n",
    "    trial[\"expanded_data\"] = pd.concat(expanded_data, ignore_index=True)\n",
    "    print(f\"Expanded data for {trial['estimand']}: {len(trial['expanded_data'])} rows\")\n",
    "    return trial\n",
    "\n",
    "trial_pp = set_expansion_options(trial_pp, chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Initialize trial_itt\n",
    "trial_itt = {\"estimand\": \"ITT\", \"dir\": trial_itt_dir}\n",
    "\n",
    "# Ensure all functions return the updated trial\n",
    "trial_itt = set_data(trial_itt, data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
    "# Add print to debug\n",
    "print(\"trial_itt before set_outcome_model:\", trial_itt)\n",
    "\n",
    "# Call set_outcome_model\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "def display_expanded_data(trial, chunk_size):\n",
    "    \"\"\"\n",
    "    Display the expanded trial data in a format similar to the R output.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: Dictionary containing trial settings and expanded data (as a DataFrame)\n",
    "    - chunk_size: The chunk size used for expansion\n",
    "    \"\"\"\n",
    "    # Extract the expanded data DataFrame\n",
    "    expanded_data = trial[\"expanded_data\"]\n",
    "    \n",
    "    # Define the columns to display (based on the R output)\n",
    "    display_columns = [\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"weight\", \n",
    "                       \"treatment\", \"x2\", \"age\", \"assigned_treatment\"]\n",
    "    \n",
    "    # Check if all required columns exist in the data\n",
    "    for col in display_columns:\n",
    "        if col not in expanded_data.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in expanded data.\")\n",
    "            return\n",
    "    \n",
    "    # Create a subset of the data with the selected columns\n",
    "    display_data = expanded_data[display_columns]\n",
    "    \n",
    "    # Display summary information\n",
    "    print(\"## Sequence of Trials Data: \")\n",
    "    print(f\"## - Chunk size: {chunk_size} \")\n",
    "    print(\"## - Censor at switch: TRUE \")\n",
    "    print(\"## - First period: 0 | Last period: Inf \")\n",
    "    print(\"##  \")\n",
    "    print(\"## A TE Datastore Datatable object \")\n",
    "    print(f\"## N: {len(display_data)} observations \")\n",
    "    \n",
    "    # Display the first two and last two rows\n",
    "    head = display_data.head(2)\n",
    "    tail = display_data.tail(2)\n",
    "    display_df = pd.concat([head, tail])\n",
    "    \n",
    "    # Print column headers with fixed width\n",
    "    print(\"## \", end=\"\")\n",
    "    for col in display_columns:\n",
    "        print(f\"{col:<15}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Print data types based on column content\n",
    "    print(\"## \", end=\"\")\n",
    "    for col in display_columns:\n",
    "        if col in [\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"treatment\", \"assigned_treatment\"]:\n",
    "            print(f\"{'<int>':<15}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{'<num>':<15}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Print the data rows\n",
    "    for idx, row in enumerate(display_df.itertuples(index=False), 1):\n",
    "        # Adjust index for tail rows\n",
    "        if idx > 2:\n",
    "            idx = len(display_data) - (4 - idx)\n",
    "        print(f\"## {idx:>3}: \", end=\"\")\n",
    "        for i, col in enumerate(display_columns):\n",
    "            value = getattr(row, col)\n",
    "            if col in [\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"treatment\", \"assigned_treatment\"]:\n",
    "                print(f\"{int(value):>10}\", end=\" \")\n",
    "            else:\n",
    "                print(f\"{value:>10.7f}\", end=\" \")\n",
    "        print()\n",
    "        # Add separator after the second row\n",
    "        if idx == 2:\n",
    "            print(\"## ---\")\n",
    "            \n",
    "print(\"PEEPEE\")\n",
    "\n",
    "display_expanded_data(trial_pp, chunk_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
